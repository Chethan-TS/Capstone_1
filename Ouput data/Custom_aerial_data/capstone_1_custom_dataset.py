# -*- coding: utf-8 -*-
"""Capstone_1_custom_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CPscpQ9REGQ8VUMUHQ--N_NNCeJB5gaj

Required Libraries
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import shutil
import random
from glob import glob

!pip install ultralytics
from ultralytics import YOLO

from google.colab import drive
drive.mount('/content/drive')

"""Importing datset to my colab enviornment"""

!mkdir -p /content/drive/MyDrive/Dataset/dataset_veh
!unzip -q "/content/drive/MyDrive/Dataset/dataset_veh.zip" -d "/content/drive/MyDrive/Dataset/dataset_veh"

"""Step 1: Implementing Background Subtraction
1. Frame differencing
2. Running average
3. Gaussian Mixture(MOG2)
3. K-Nearest Neighbors (KNN)

Step 2: Post processing

Step 3: Fusion of BGS

Step 4: Visualization
"""

# --- Input/output Configuration ---
input_dir = "/content/drive/MyDrive/Dataset/dataset_veh/dataset/train/images"
output_dir = "/content/drive/MyDrive/Dataset/dataset_veh/BGS_masks"
os.makedirs(output_dir, exist_ok=True)

methods = ["frame_diff", "running_avg", "mog2", "knn", "fused_majority", "fused_weighted"]
for method in methods:
    os.makedirs(os.path.join(output_dir, method), exist_ok=True)

# --- Utility: Post-processing ---
def post_process(mask, kernel_size=5, min_area=500):
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    clean_mask = np.zeros_like(mask)
    for cnt in contours:
        if cv2.contourArea(cnt) >= min_area:
            cv2.drawContours(clean_mask, [cnt], -1, 255, -1)
    return clean_mask

# --- Visualize image ----
def show_multiple(title, images, titles, cols=3):
    rows = (len(images) + cols - 1) // cols
    fig, axs = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))
    axs = axs.flatten()
    for i, (img, t) in enumerate(zip(images, titles)):
        axs[i].imshow(img, cmap='gray')
        axs[i].set_title(t)
        axs[i].axis("off")
    for i in range(len(images), len(axs)):
        axs[i].axis("off")
    fig.suptitle(title, fontsize=16)
    plt.tight_layout()
    plt.show()

# --- BGS Methods Initialization ---
mog2 = cv2.createBackgroundSubtractorMOG2()
knn = cv2.createBackgroundSubtractorKNN()
alpha = 0.01
running_avg_initialized = False

# --- Frame Loading ---
image_files = sorted([f for f in os.listdir(input_dir) if f.endswith(('.jpg', '.png'))])
prev_frame = None
VIS_FRAME_IDX = 2

# To store visualizations for 1 image
vis_raw = {}
vis_post = {}
vis_fused = {}

for i, filename in enumerate(tqdm(image_files, desc="Processing frames")):
    path = os.path.join(input_dir, filename)
    frame = cv2.imread(path)
    frame = cv2.resize(frame, (960, 540))
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    masks = {}

    # --- 1. Frame Differencing ---
    if prev_frame is not None:
        diff = cv2.absdiff(gray, prev_frame)
        _, mask_diff = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)
    else:
        mask_diff = np.zeros_like(gray)
    prev_frame = gray.copy()
    masks["frame_diff"] = mask_diff.copy()

    # --- 2. Running Average ---
    if not running_avg_initialized:
        avg = np.float32(gray)
        running_avg_initialized = True
    cv2.accumulateWeighted(gray, avg, alpha)
    res = cv2.convertScaleAbs(avg)
    diff_ra = cv2.absdiff(gray, res)
    _, mask_ra = cv2.threshold(diff_ra, 25, 255, cv2.THRESH_BINARY)
    masks["running_avg"] = mask_ra.copy()

    # --- 3. MOG2 ---
    masks["mog2"] = mog2.apply(frame)

    # --- 4. KNN ---
    masks["knn"] = knn.apply(frame)

    # Store raw masks if this is the visualized frame
    if i == VIS_FRAME_IDX:
        vis_raw = {k: v.copy() for k, v in masks.items()}

    # --- Post-process and save ---
    for key in masks:
        masks[key] = post_process(masks[key])
        cv2.imwrite(os.path.join(output_dir, key, filename), masks[key])

    if i == VIS_FRAME_IDX:
        vis_post = {k: v.copy() for k, v in masks.items()}

    # --- 5. Majority Voting ---
    stack = np.stack([masks["frame_diff"], masks["running_avg"], masks["mog2"], masks["knn"]], axis=-1)
    majority_mask = np.where(np.sum(stack > 0, axis=-1) >= 3, 255, 0).astype(np.uint8)
    majority_mask = post_process(majority_mask)
    cv2.imwrite(os.path.join(output_dir, "fused_majority", filename), majority_mask)

    # --- 6. Weighted Fusion ---
    weights = {"frame_diff": 0.2, "running_avg": 0.2, "mog2": 0.3, "knn": 0.3}
    fused = (weights["frame_diff"] * masks["frame_diff"] +
             weights["running_avg"] * masks["running_avg"] +
             weights["mog2"] * masks["mog2"] +
             weights["knn"] * masks["knn"])
    _, weighted_mask = cv2.threshold(fused.astype(np.uint8), 127, 255, cv2.THRESH_BINARY)
    weighted_mask = post_process(weighted_mask)
    cv2.imwrite(os.path.join(output_dir, "fused_weighted", filename), weighted_mask)

    if i == VIS_FRAME_IDX:
        vis_fused = {
            "fused_majority": majority_mask.copy(),
            "fused_weighted": weighted_mask.copy()
        }

# --- Final Visualization for selected frame ---
show_multiple("Raw BGS Masks", list(vis_raw.values()), list(vis_raw.keys()))
show_multiple("Post-Processed BGS Masks", list(vis_post.values()), list(vis_post.keys()))
show_multiple("Fused Masks", list(vis_fused.values()), list(vis_fused.keys()))

"""Pseudo Labling the images based on generated BGS masks"""

# --- Config ---
bgs_methods = ["fused_majority", "fused_weighted"]
mask_root = "/content/drive/MyDrive/Dataset/dataset_veh/BGS_masks"
image_dir = "/content/drive/MyDrive/Dataset/dataset_veh/dataset/train/images"
output_root = "/content/drive/MyDrive/Dataset/dataset_veh/BGS_labels"

# --- Create output dirs ---
for method in bgs_methods:
    os.makedirs(os.path.join(output_root, method), exist_ok=True)

# --- Convert BGS masks to YOLO labels ---
for method in bgs_methods:
    mask_dir = os.path.join(mask_root, method)
    output_dir = os.path.join(output_root, method)

    for filename in sorted(os.listdir(mask_dir)):
        if not filename.endswith(('.png', '.jpg')):
            continue

        mask_path = os.path.join(mask_dir, filename)
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            continue

        img_path = os.path.join(image_dir, filename)
        img = cv2.imread(img_path)
        if img is None:
            continue
        h, w = img.shape[:2]

        # Extract contours (connected foreground regions)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        yolo_lines = []
        for cnt in contours:
            x, y, bw, bh = cv2.boundingRect(cnt)

            # Normalize
            x_center = (x + bw / 2) / w
            y_center = (y + bh / 2) / h
            norm_bw = bw / w
            norm_bh = bh / h

            # Filter noise (very small boxes)
            if norm_bw < 0.01 or norm_bh < 0.01:
                continue

            yolo_lines.append(f"0 {x_center:.6f} {y_center:.6f} {norm_bw:.6f} {norm_bh:.6f}")

        # Save to file
        label_path = os.path.join(output_dir, filename.rsplit('.', 1)[0] + '.txt')
        with open(label_path, 'w') as f:
            f.write('\n'.join(yolo_lines))

"""Visualize sample images with psuedo labels"""

# --- Config ---
image_dir = "/content/drive/MyDrive/Dataset/dataset_veh/dataset/train/images"
label_root = "/content/drive/MyDrive/Dataset/dataset_veh/BGS_labels"
methods = ["fused_majority", "fused_weighted"]
num_samples = 5  # Number of images per method to visualize

# --- Helper: Draw YOLO boxes on image ---
def draw_boxes(img, label_path):
    h, w = img.shape[:2]
    if not os.path.exists(label_path):
        return img

    with open(label_path, 'r') as f:
        for line in f.readlines():
            parts = line.strip().split()
            if len(parts) != 5:
                continue
            _, x_c, y_c, bw, bh = map(float, parts)
            x1 = int((x_c - bw / 2) * w)
            y1 = int((y_c - bh / 2) * h)
            x2 = int((x_c + bw / 2) * w)
            y2 = int((y_c + bh / 2) * h)
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    return img

# --- Visualization ---
for method in methods:
    label_dir = os.path.join(label_root, method)
    image_files = sorted(os.listdir(image_dir))[:num_samples]

    print(f"\nüîç Showing results for: {method.upper()}")
    for filename in image_files:
        img_path = os.path.join(image_dir, filename)
        label_path = os.path.join(label_dir, filename.rsplit('.', 1)[0] + ".txt")

        img = cv2.imread(img_path)
        if img is None:
            continue
        img_boxed = draw_boxes(img.copy(), label_path)

        plt.figure(figsize=(8, 6))
        plt.imshow(cv2.cvtColor(img_boxed, cv2.COLOR_BGR2RGB))
        plt.title(f"{method}: {filename}")
        plt.axis("off")
        plt.show()

"""Preparing data set for training

10% images with labels

90% images without labels
"""

# --- Config ---
image_dir = "/content/drive/MyDrive/Dataset/dataset_veh/dataset/train/images"
label_dir = "/content/drive/MyDrive/Dataset/dataset_veh/dataset/train/labels"
pseudo_label_dir = "/content/drive/MyDrive/Dataset/dataset_veh/BGS_labels/fused_weighted"

output_base = "/content/drive/MyDrive/Dataset/dataset_veh/YOLO_dataset"
subfolders = [
    "images/train", "images/train_labeled", "images/train_unlabeled",
    "labels/train", "labels/train_labeled", "labels/train_unlabeled"
]
for sf in subfolders:
    os.makedirs(os.path.join(output_base, sf), exist_ok=True)

# --- Select 10% real labeled ---
all_images = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))])
sample_count = int(0.10 * len(all_images))
real_sample = random.sample(all_images, sample_count)
real_sample_set = set(real_sample)

# --- Step 1: Copy 10% real-labeled images and labels ---
for fname in real_sample:
    base = os.path.splitext(fname)[0]
    real_label_path = os.path.join(label_dir, base + ".txt")
    if not os.path.exists(real_label_path):
        continue

    # Copy to combined train
    shutil.copy(os.path.join(image_dir, fname), f"{output_base}/images/train/{fname}")
    shutil.copy(real_label_path, f"{output_base}/labels/train/{base}.txt")

    # Also copy to train_labeled
    shutil.copy(os.path.join(image_dir, fname), f"{output_base}/images/train_labeled/{fname}")
    shutil.copy(real_label_path, f"{output_base}/labels/train_labeled/{base}.txt")

# --- Step 2: Copy 90% pseudo-labeled ---
for fname in all_images:
    if fname in real_sample_set:
        continue

    base = os.path.splitext(fname)[0]
    pseudo_label_path = os.path.join(pseudo_label_dir, base + ".txt")
    if not os.path.exists(pseudo_label_path):
        continue

    # Copy to combined train
    shutil.copy(os.path.join(image_dir, fname), f"{output_base}/images/train/{fname}")
    shutil.copy(pseudo_label_path, f"{output_base}/labels/train/{base}.txt")

    # Also copy to train_unlabeled
    shutil.copy(os.path.join(image_dir, fname), f"{output_base}/images/train_unlabeled/{fname}")
    #shutil.copy(pseudo_label_path, f"{output_base}/labels/train_unlabeled/{base}.txt")

print("‚úÖ Organized dataset at /content/YOLO_dataset with full structure.")

"""Preparing validation dataste"""

# Source (converted validation set from final_dataset)
val_img_src = "/content/drive/MyDrive/Dataset/dataset_veh/dataset/valid/images"
val_lbl_src = "/content/drive/MyDrive/Dataset/dataset_veh/dataset/valid/labels"

# Destination in YOLO_dataset
val_img_dst = "/content/drive/MyDrive/Dataset/dataset_veh/YOLO_dataset/images/val"
val_lbl_dst = "/content/drive/MyDrive/Dataset/dataset_veh/YOLO_dataset/labels/val"

# Create destination folders
os.makedirs(val_img_dst, exist_ok=True)
os.makedirs(val_lbl_dst, exist_ok=True)

for fname in os.listdir(val_img_src):
    if fname.endswith(".jpg") or fname.endswith(".png"):
        shutil.copy(os.path.join(val_img_src, fname), os.path.join(val_img_dst, fname))

for fname in os.listdir(val_lbl_src):
    if fname.endswith(".txt"):
        shutil.copy(os.path.join(val_lbl_src, fname), os.path.join(val_lbl_dst, fname))

"""Verify the Dataset"""

base_path = "/content/drive/MyDrive/Dataset/dataset_veh/YOLO_dataset"

# Expected subfolders
expected_paths = [
    "images/train",
    "images/val",
    "images/train_labeled",
    "images/train_unlabeled",
    "labels/train",
    "labels/val",
    "labels/train_labeled",
    "labels/train_unlabeled"
]

print("‚úÖ Checking folder structure:")
for sub_path in expected_paths:
    full_path = os.path.join(base_path, sub_path)
    if os.path.exists(full_path):
        print(f"‚úÖ Found: {full_path}")
        # Count files
        files = glob(f"{full_path}/*")
        print(f"   ‚Üí {len(files)} files")
    else:
        print(f"‚ùå Missing: {full_path}")

# Print example image-label match
train_images = sorted(glob(f"{base_path}/images/train/*.jpg"))
train_labels = sorted(glob(f"{base_path}/labels/train/*.txt"))

print("\n‚úÖ Sample train image-label pairings:")
for img, lbl in zip(train_images[:3], train_labels[:3]):
    print(f"   üñº {os.path.basename(img)} ‚Üî üè∑ {os.path.basename(lbl)}")

"""Create an yaml file for train and validation"""

data_yaml = """
path: /content/drive/MyDrive/Dataset/dataset_veh/YOLO_dataset
train: images/train
val: images/val

nc: 1
names:
  0: cars
"""

with open("/content/drive/MyDrive/Dataset/dataset_veh/data.yaml", "w") as f:
    f.write(data_yaml.strip())

"""Train a Deep learning YOLO modol"""

model = YOLO("yolov8s.pt")  # or yolov8n.pt, etc.

model.train(
    data="/content/drive/MyDrive/Dataset/dataset_veh/data.yaml",
    epochs=100,
    imgsz=640,
    project="semi_supervised",
    name="10_percent_train",
    exist_ok=True
)

"""Validate the model on validation dataset and get the results"""

# Load your best trained model
model = YOLO("/content/semi_supervised/10_percent_train/weights/best.pt")

# Run validation on the val set from your data.yaml
metrics = model.val(data="/content/drive/MyDrive/Dataset/dataset_veh/data.yaml")

results = metrics.results_dict  # or metrics if already a dict

# Extract precision and recall
precision = results['metrics/precision(B)']
recall = results['metrics/recall(B)']

# Calculate F1-score
if precision + recall > 0:
    f1_score = 2 * (precision * recall) / (precision + recall)
else:
    f1_score = 0.0

print("üìä YOLOv8 Evaluation Metrics")
print("-" * 40)
print(f"üîπ Precision      : {results['metrics/precision(B)']:.4f}")
print(f"üîπ Recall         : {results['metrics/recall(B)']:.4f}")
print(f"üîπ F1 Score       : {f1_score:.4f}")
print(f"üîπ mAP@0.5        : {results['metrics/mAP50(B)']:.4f}")
print(f"üîπ mAP@0.5:0.95   : {results['metrics/mAP50-95(B)']:.4f}")
print("-" * 40)
print(f"üèÅ Fitness Score  : {results['fitness']:.4f}")

"""Run a prediction model on unlabeled *images*"""

# Paths
unlabeled_dir = "/content/drive/MyDrive/Dataset/dataset_veh/YOLO_dataset/images/train_unlabeled"
predicted_labels_dir = "/content/drive/MyDrive/Dataset/dataset_veh/YOLO_dataset/labels/train_unlabeled"
os.makedirs(predicted_labels_dir, exist_ok=True)

# Predict & save labels
model.predict(
    source=unlabeled_dir,
    save_txt=True,
    save_conf=True,
    conf=0.25,
    project="predictions",
    name="train_unlabeled_preds",
    exist_ok=True
)

"""Use predicted labes for labling ublabeled images"""

# Paths
predicted_labels = "/content/predictions/train_unlabeled_preds/labels"
train_unlabeled_set = "/content/drive/MyDrive/Dataset/dataset_veh/YOLO_dataset/images/train_unlabeled"
target_train_labels = "/content/drive/MyDrive/Dataset/dataset_veh/YOLO_dataset/labels/train"

# Get filenames (only base names, without extension)
unlabeled_filenames = [os.path.splitext(f)[0] for f in os.listdir(train_unlabeled_set)]

count = 0
for fname in unlabeled_filenames:
    src = os.path.join(predicted_labels, fname + ".txt")
    dst = os.path.join(target_train_labels, fname + ".txt")
    if os.path.exists(src):
        shutil.copyfile(src, dst)
        count += 1

print(f"‚úÖ Replaced {count} BGS pseudo-labels with model predictions.")

"""Run a Training model with predicted labels"""

model.train(
    data="/content/drive/MyDrive/Dataset/dataset_veh/data.yaml",
    epochs=100,
    imgsz=640,
    project="semi_supervised",
    name="final_train_with_refined_labels",
    exist_ok=True
)

"""Evaluate the model"""

metrics = model.val(data="/content/drive/MyDrive/Dataset/dataset_veh/data.yaml")

results = metrics.results_dict  # or metrics if already a dict

# Extract precision and recall
precision = results['metrics/precision(B)']
recall = results['metrics/recall(B)']

# Calculate F1-score
if precision + recall > 0:
    f1_score = 2 * (precision * recall) / (precision + recall)
else:
    f1_score = 0.0

print("üìä YOLOv8 Evaluation Metrics")
print("-" * 40)
print(f"üîπ Precision      : {results['metrics/precision(B)']:.4f}")
print(f"üîπ Recall         : {results['metrics/recall(B)']:.4f}")
print(f"üîπ F1 Score       : {f1_score:.4f}")
print(f"üîπ mAP@0.5        : {results['metrics/mAP50(B)']:.4f}")
print(f"üîπ mAP@0.5:0.95   : {results['metrics/mAP50-95(B)']:.4f}")
print("-" * 40)
print(f"üèÅ Fitness Score  : {results['fitness']:.4f}")

"""Compare both models"""

# Load both models
initial_model = YOLO("/content/semi_supervised/10_percent_train/weights/best.pt")
final_model = YOLO("/content/semi_supervised/final_train_with_refined_labels/weights/best.pt")

# Evaluate both
initial_results = initial_model.val(data="/content/drive/MyDrive/Dataset/dataset_veh/data.yaml", split='val')
final_results = final_model.val(data="/content/drive/MyDrive/Dataset/dataset_veh/data.yaml", split='val')

# Print key metrics
print("üìä Initial Model Metrics:")
print(f"mAP50: {initial_results.box.map50:.4f}")
print(f"mAP50-95: {initial_results.box.map:.4f}")

print("\nüìä Final Model Metrics (with refined pseudo-labels):")
print(f"mAP50: {final_results.box.map50:.4f}")
print(f"mAP50-95: {final_results.box.map:.4f}")

"""Select some sample images with validate set and and label it"""

# Select some random validation images
val_images = sorted(glob("/content/drive/MyDrive/Dataset/dataset_veh/YOLO_dataset/images/val/*.jpg"))
sample_imgs = random.sample(val_images, 5)

# Load models
initial_model = YOLO("/content/semi_supervised/10_percent_train/weights/best.pt")
final_model = YOLO("/content/semi_supervised/final_train_with_refined_labels/weights/best.pt")

for img_path in sample_imgs:
    # Predict
    initial_preds = initial_model.predict(source=img_path, conf=0.25, save=False, verbose=False)
    final_preds = final_model.predict(source=img_path, conf=0.25, save=False, verbose=False)

    # Extract predicted images
    img_initial = initial_preds[0].plot()
    img_final = final_preds[0].plot()

    # Plot side-by-side
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.title("Initial Model (10% real + BGS)")
    plt.imshow(cv2.cvtColor(img_initial, cv2.COLOR_BGR2RGB))
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.title("Final Model (10% real + refined preds)")
    plt.imshow(cv2.cvtColor(img_final, cv2.COLOR_BGR2RGB))
    plt.axis("off")

    plt.tight_layout()
    plt.show()

"""Test it on a video"""

# --- Load YOLOv8 model ---
model_path = YOLO("/content/semi_supervised/final_train_with_refined_labels/weights/best.pt")
model = YOLO(model_path)

# --- Input and Output paths ---
input_video_path = "/content/drive/MyDrive/Dataset/dataset_veh/dataset/sample_video.mp4"
output_video_path = "/content/drive/MyDrive/Dataset/dataset_veh/dataset/output_result.mp4"

# --- Open video input and get properties ---
cap = cv2.VideoCapture(input_video_path)
if not cap.isOpened():
    raise Exception(f"Failed to open input video: {input_video_path}")

fps = cap.get(cv2.CAP_PROP_FPS)
w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# --- Prepare video writer ---
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))

# --- Frame-by-frame inference ---
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    results = model.predict(source=frame, conf=0.4, iou=0.5, stream=False)
    annotated_frame = results[0].plot()
    out.write(annotated_frame)

cap.release()
out.release()
print(f"‚úÖ Detection video saved at: {output_video_path}")

import shutil
from google.colab import files

# Replace with the path to your folder
folder_path = "/content/semi_supervised"
zip_path = "/content/semi_supervised.zip"

# Zip the folder
shutil.make_archive(zip_path.replace(".zip", ""), 'zip', folder_path)

# Download the zip
files.download(zip_path)

